@article{,
   abstract = {The aim of this research is to provide an overview of the most widely used types of software development methodologies and their fields of application. The methodology used was Systemic Literature Review. In the first place, the search criteria were defined, then the search was carried out selecting the works that met these criteria, later the fields to be analyzed were established and organized in a table, finally the selected data were processed and analyzed. 105 articles were collected, of which 101 specified the necessary information. It is concluded that agile methodologies are the most used with 86.31% and within them SCRUM represents 41.98%. In addition, the type of multiplatform development was analyzed where the most used methodologies were Scrum with 40% and Mobile-D with 25%.},
   author = {Jessica Morales-Carrillo and Luis Cedeño-Valarezo and Jesús Stefano Cajape Bravo and Jonathan Geovanny Ormaza Calderón},
   issn = {16469895},
   issue = {Special Issue 47},
   journal = {RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao},
   keywords = {Agile,Methodology,Multiplatform,Software,traditional},
   month = {1},
   pages = {29-45},
   publisher = {Associacao Iberica de Sistemas e Tecnologias de Informacao},
   title = {Software development methodologies: fields of application},
   volume = {2022},
   year = {2022},
}
@web_page{,
   title = {Authoring Tool Accessibility Guidelines (ATAG) 2.0},
   url = {https://www.w3.org/TR/ATAG20/#guidelines},
}
@web_page{,
   title = {Authoring Tool Accessibility Guidelines (ATAG) 2.0},
   url = {https://www.w3.org/TR/ATAG20/#guidelines},
}
@article{Ranga2019,
   abstract = {Web Services are combination of open protocols and standards to allow communication between client and server. It provides an interoperability between contrasting applications. Representational state Transfer (REST) and Simple Object Access Protocol (SOAP) are the two main popular used web services now-a-days. REST is an architectural style based, whereas SOAP is a underlying protocol. Both services are used to handle the communication on the world wide web (www). Both services have some advantages and drawbacks and it is the decision of web developer to decide which service is best to use according to its requirements. The aim of this research work is to design a REST API and SOAP API by JAX-RS and JAX-WS, respectively and gives a comparative analysis of Application Programming Interface (API) features (in terms of response time, memory usage, execution speed and so on) of these services by using API testing tool like Postman. This gives insight view of which service is better to use as per requirements. The result of experiments shows that the response time of SOAP is approximate takes 4ms to 7ms more than REST. It has been observed that as number of API increases, SOAP takes approximate 1MB to 2MB more memory usage than REST.},
   author = {Virender Ranga and Anshu Soni},
   doi = {10.35940/ijitee.I1107.0789S19},
   issue = {8},
   journal = {Article in International Journal of Innovative Technology and Exploring Engineering},
   keywords = {Index Terms: Architectural style,JAX-RS,JAX-WS,Jersey,Postman,Protocol,REST,SOAP,Tomcat,Web service},
   pages = {2278-3075},
   title = {API Features Individualizing of Web Services: REST and SOAP Hybrid Framework for FANets View project API Features Individualizing of Web Services: REST and SOAP View project},
   url = {https://www.researchgate.net/publication/335419384},
   year = {2019},
}
@article{Huf2019,
   abstract = {Initial developments in Service-Oriented Computing (SOC) led to the development of Web Services using the SOAP protocol and an extensive set of tools and methods for composing new services from those existing. Subsequently, other types of services also emerged, such as event-oriented services and RESTful services. Nevertheless, all mentioned service types expose data and functionality, and users can benefit from their composition, regardless of the service type chosen for their implementation. In the Internet of Things, it is relevant to employ event-oriented services for sensing and SOAP, RESTful or lightweight web APIs for control. In the emerging field of microservices, heterogeneity is embraced as a design principle and services that are part of a single system may be implemented using heterogeneous technologies and paradigms. The research question of this review is: How heterogeneous services can be composed? There are several surveys that cover service composition with each of the existing service types, but the composition of heterogeneous services is only marginally addressed. This systematic literature review focuses explicitly on the heterogeneity of the aforementioned service types. A total of 66 documents, published from 2005 to 2018, have been surveyed, targeting all possible combinations of the three service types. In addition to summarizing existing works, the specific methods employed for supporting service type heterogeneity are grouped into archetypes and have their limitations and capabilities analyzed. Despite the large number of documents found, there are several open issues on heterogeneous service composition. The results of this review are confronted with emerging fields in service computing, namely microservices, serverless and IoT, yielding additional research directions.},
   author = {Alexis Huf and Frank Siqueira},
   doi = {10.1016/J.JNCA.2019.06.008},
   issn = {10958592},
   journal = {Journal of Network and Computer Applications},
   keywords = {Event-oriented services,Heterogeneous services,Microservices,RESTful services,SOAP services,Web service composition},
   month = {10},
   pages = {89-110},
   publisher = {Academic Press},
   title = {Composition of heterogeneous web services: A systematic review},
   volume = {143},
   year = {2019},
}
@article{Ranga2019,
   abstract = {Web Services are combination of open protocols and standards to allow communication between client and server. It provides an interoperability between contrasting applications. Representational state Transfer (REST) and Simple Object Access Protocol (SOAP) are the two main popular used web services now-a-days. REST is an architectural style based, whereas SOAP is a underlying protocol. Both services are used to handle the communication on the world wide web (www). Both services have some advantages and drawbacks and it is the decision of web developer to decide which service is best to use according to its requirements. The aim of this research work is to design a REST API and SOAP API by JAX-RS and JAX-WS, respectively and gives a comparative analysis of Application Programming Interface (API) features (in terms of response time, memory usage, execution speed and so on) of these services by using API testing tool like Postman. This gives insight view of which service is better to use as per requirements. The result of experiments shows that the response time of SOAP is approximate takes 4ms to 7ms more than REST. It has been observed that as number of API increases, SOAP takes approximate 1MB to 2MB more memory usage than REST.},
   author = {Virender Ranga and Anshu Soni},
   doi = {10.35940/ijitee.I1107.0789S19},
   issue = {8},
   journal = {Article in International Journal of Innovative Technology and Exploring Engineering},
   keywords = {Index Terms: Architectural style,JAX-RS,JAX-WS,Jersey,Postman,Protocol,REST,SOAP,Tomcat,Web service},
   pages = {2278-3075},
   title = {API Features Individualizing of Web Services: REST and SOAP Hybrid Framework for FANets View project API Features Individualizing of Web Services: REST and SOAP View project},
   url = {https://www.researchgate.net/publication/335419384},
   year = {2019},
}
@article{Ali2018,
   abstract = {Mobile computing in conjunction with Mobile web services drives a strong approach where the limitations of mobile devices may possibly be tackled. Mobile Web Services are based on two types of technologies; SOAP and REST, which works with the existing protocols to develop Web services. Both the approaches carry their own distinct features, yet to keep the constraint features of mobile devices in mind, the better in two is considered to be the one which minimize the computation and transmission overhead while offloading. The load transferring of mobile device to remote servers for execution called computational offloading. There are numerous approaches to implement computational offloading a viable solution for eradicating the resources constraints of mobile device, yet a dynamic method of computational offloading is always required for a smooth and simple migration of complex tasks. The intention of this work is to present a distinctive approach which may not engage the mobile resources for longer time. The concept of web services utilized in our work to delegate the computational intensive tasks for remote execution. We tested both SOAP Web services approach and REST Web Services for mobile computing. Two parameters considered in our lab experiments to test; Execution Time and Energy Consumption. The results show that RESTful Web services execution is far better than executing the same application by SOAP Web services approach, in terms of execution time and energy consumption. Conducting experiments with the developed prototype matrix multiplication app, REST execution time is about 200% better than SOAP execution approach. In case of energy consumption REST execution is about 250% better than SOAP execution approach.},
   author = {Mushtaq Ali and Mohamad Fadli Zolkipli and Jasni Mohamad Zain and Shahid Anwar},
   doi = {10.1088/1742-6596/1018/1/012005},
   journal = {J. Phys},
   keywords = {Battery Consumption,Execution Time,Rest Webservices,Soap Webservices},
   pages = {12005},
   title = {Mobile Cloud Computing with SOAP and REST Web Services},
   year = {2018},
}
@article{Costa2019,
   abstract = {Service-oriented architecture (SOA) is being increasingly used by developers both in web applications and in mobile applications. Within web services there are two main implementations: SOAP communication protocol and REST. This work presents a comparative study of performance between these two types of web services, SOAP versus REST, as well as analyses factors that may affect the efficiency of applications that are based on this architecture. In this experimental evaluation we used an application deployed in a Wildfly server and then used the JMeter test tool to launch requests in different numbers of threads and calls. Contrary to the more general idea that REST web services are significantly faster than SOAP, our results show that REST web services are 1% faster than SOAP. As this programming paradigm is increasingly used in a growing number of client and server applications, we conclude that the REST implementation is more efficient for systems which have to respond to less calls but have more requests in a connection.},
   author = {Pedro Costa Silva and Jorge Bernardino},
   doi = {10.5220/0007979205700576},
   isbn = {9789897583797},
   keywords = {Performance,Rest,SOA,Soap,Web Services},
   title = {Java Web Services: A Performance Analysis},
   url = {https://orcid.org/0000-0001-9660-2011},
   year = {2019},
}
@report{Johnson2018,
   author = {Charlotte, North Carolina Johnson C. Smith University},
   title = {Oracle Database Programming with Java},
   year = {2018},
}
@book{Guerrero2022,
   author = {Gleiston Guerrero Ulloa},
   isbn = {9789942335432},
   title = {Tecnologías para el desarrollo de aplicaciones web},
   year = {2022},
}
@article{Ekie2021,
   abstract = {Web services are an attracting area that interest many researchers and industrial organizations. Given the convenience and reusability, web services have become a main mode of cloud application. Web services can be developed based on two interaction styles such as Simple Object Access Protocol (SOAP) and Representational State Transfer Protocol (REST). Nevertheless, the function of single web service is usually too simple to satisfy the user's complex demand. Therefore, it is necessary to combine a set of basic web services in order to create a composite web services. However, most existing work on the comparison of SOAP and REST focuses on a single micro-service and fails to outline the performance of those two approaches in a real-case situation where, most of the time, multiple micro-services are bound together to provide a more holistic answer to user requests. In this paper, we try to tackle this issue from a more business-centered perspective. We use a case study involving multiple services both in local and remote Cloud environments with SOAP Web services composition and REST Web services composition. The first environment will help us find out the behavior in a more controlled situation compared to the latter where multiple service providers are involved.},
   author = {Jesus Ekie and Bassirou Gueye and Ibrahima Niang},
   doi = {10.1145/3454127.3457621},
   isbn = {9781450388719},
   keywords = {Cloud computing,Comparative analysis,REST,SOAP,Web service composition,service invocation performance},
   title = {A comparative analysis of SOAP and REST Web service composition based on performance in local and remote Cloud environments; A comparative analysis of SOAP and REST Web service composition based on performance in local and remote Cloud environments},
   url = {https://doi.org/10.1145/3454127.3457621},
   year = {2021},
}
@article{Zhou2012,
   author = {Jiehan Zhou},
   doi = {10.1108/17427371111189665},
   journal = {International Journal of Pervasive Computing and Communications},
   title = {Perception framework for supporting development of contextaware web services Cite this paper Related papers},
   url = {http://dx.doi.org/10.1108/17427371111189665},
   year = {2012},
}
@article{Ireland2021,
   abstract = {Motivation: Many bioinformatics resources are provided as 'web services', with large databases and analysis software stored on a central server, and clients interacting with them using the hypertext transport protocol (HTTP). While some provide only a visual HTML interface, requiring a web browser to use them, many provide programmat-ic access using a web application programming interface (API) which returns XML, JSON or plain text that computer programs can interpret more easily. This allows access to be automated. Initially, many bioinformatics APIs used the 'simple object access protocol' (SOAP) and, more recently, representational state transfer (REST). Results: GraphQL is a novel, increasingly prevalent alternative to REST and SOAP that represents the available data in the form of a graph to which any conceivable query can be submitted, and which is seeing increasing adoption in industry. Here, we review the principles of GraphQL, outline its particular suitability to the delivery of bioinformatics resources and describe its implementation in our ZincBind resource. Availability and implementation: https://api.},
   author = {Sam M Ireland and Andrew C R Martin},
   doi = {10.1093/bioadv/vbab023},
   title = {GraphQL for the delivery of bioinformatics web APIs and application to ZincBind},
   url = {https://www.},
   year = {2021},
}
@article{Chakravarthy2021,
   abstract = {Web services are the way of integrating the web related applications using the XML, SOAP, WSDL and UDDI protocols in a standardized manner. Web service composition is the primary task of composing variety of different services on composite applications. Effective web service composition is not an easy task. This paper proposes a novel framework for extracting the interesting actionable patterns for effective web services for composition. This algorithm utilizes utility based data mining for extracting high utility actionable patterns for web service composition. Experimental results show that HUI-Miner approach outperforms well in terms of running time efficiency for our framework.},
   author = {D. Gowtham Chakravarthy and S. Kannimuthu},
   doi = {10.1007/S12652-020-02187-5},
   issn = {18685145},
   issue = {6},
   journal = {Journal of Ambient Intelligence and Humanized Computing},
   keywords = {Interesting patterns,Semantic measures,Utility mining,Web service,Web service composition,XML},
   month = {6},
   pages = {6181-6187},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Mining interesting actionable patterns for web service composition},
   volume = {12},
   year = {2021},
}
@article{Halili2018,
   abstract = {The interest on Web services has been growing rapidly in these couple of years since their start of use. A web service would be described as a method for exchanging/communicating information between devices over a network. Often, when deciding which service would fit on the architecture design to develop a product, then the question rises which service to use and when?SOAP (Simple Object Access Protocol) and REST (Representational State Transfer) are the two most used protocols to exchange messages, so choosing one over the other has its own advantages and disadvantages. In this paper we have addressed the differences and best practices when to use one over the other.},
   author = {Festim Halili and Erenis Ramadani},
   doi = {10.5539/mas.v12n3p175},
   issn = {1913-1844},
   issue = {3},
   journal = {Modern Applied Science},
   month = {2},
   pages = {175},
   publisher = {Canadian Center of Science and Education},
   title = {Web Services: A Comparison of Soap and Rest Services},
   volume = {12},
   year = {2018},
}
@article{Automatic,
   abstract = {Agile methods in general and the Scrum method in particular are gaining more and more trust from the software developer community. When it comes to writing a functional requirement, user stories become more and more usable by the community. Furthermore, a considerable effort has already been made by the community in relation to the use of the use case tool when drafting requirements and in terms of model transformation. We have reached a certain stage of maturity at this level. The idea of our paper is to profit from these richness and to invest it in the drafting of user stories. In this paper, we propose a process of transforming user stories into use cases and we will be able to benefit from all the work done in the transformation of the models according to the MDA approach. To do this, we used natural language processing (NLP) techniques, by applying TreeTagger parser. Our work was validated by a case study where we were able to obtain very positive precisions between 87% and 98%.},
   author = {Meryem Elallaoui and Khalid Nafil and Raja Touahni},
   doi = {10.1016/J.PROCS.2018.04.010},
   issn = {18770509},
   journal = {Procedia Computer Science},
   keywords = {MDA,NLP,UML,Use Case,User Stories},
   pages = {42-49},
   publisher = {Elsevier B.V.},
   title = {Automatic Transformation of User Stories into UML Use Case Diagrams using NLP Techniques},
   volume = {130},
   year = {2018},
}
@article{Metamodel,
   abstract = {Interface and interaction design take up most of the times in software creation. Human Computer Interaction (HCI) is mainly the best way to interact with a computer. During software development, class diagram is the only required step and process to design an information system according to UML notation. In addition, creating class diagram is a mandatory activity during the software creation process. The aim of this paper is to automatically generate the HCI mockup from class diagram to make easy and extremely fast software design. For example, the SEF (Schéma d'Enchaînement de Fenêtre), is an interface model allowing to create a new interface mockup. It offers more widgets to design the HCI. And MACAO (Méthode d'Analyse et de Conception d'Applications Orientées-objets) is one of the methods which helps computer scientist to easily create software. The model transformation is based on Model Driven Engineering (MDE). We use UML notation to design the class diagrams. We also adopt MDA architecture to create the model-based transformation process. Transformation rules are created using Atlas Transformation Language (ATL) to automatically generate a specific interface from the class diagram.},
   author = {Mahatody Thomas and Ilie Mihaela and Rapatsalahy Miary Andrianjaka and Dimbisoa William Germain and Ilie Sorin},
   doi = {10.1016/J.PROCS.2021.03.096},
   issn = {18770509},
   journal = {Procedia Computer Science},
   keywords = {Class diagram,Human computer interaction,MACAO,Mockup,Model driven architecture,Model driven engineering,Transformation,User interface},
   pages = {779-784},
   publisher = {Elsevier B.V.},
   title = {Metamodel based approach to generate user interface mockup from UML class diagram},
   volume = {184},
   year = {2021},
}
@article{Management,
   abstract = {Context: Quality requirements (QRs) describe the desired quality of software, and they play an important role in the success of software projects. In agile software development (ASD), QRs are often ill-defined and not well addressed due to the focus on quickly delivering functionality. Rapid software development (RSD) approaches (e.g., continuous delivery and continuous deployment), which shorten delivery times, are more prone to neglect QRs. Despite the significance of QRs in both ASD and RSD, there is limited synthesized knowledge on their management in those approaches. Objective: This study aims to synthesize state-of-the-art knowledge about QR management in ASD and RSD, focusing on three aspects: bibliometric, strategies, and challenges. Research method: Using a systematic mapping study with a snowballing search strategy, we identified and structured the literature on QR management in ASD and RSD. Results: We found 156 primary studies: 106 are empirical studies, 16 are experience reports, and 34 are theoretical studies. Security and performance were the most commonly reported QR types. We identified various QR management strategies: 74 practices, 43 methods, 13 models, 12 frameworks, 11 advices, 10 tools, and 7 guidelines. Additionally, we identified 18 categories and 4 non-recurring challenges of managing QRs. The limited ability of ASD to handle QRs, time constraints due to short iteration cycles, limitations regarding the testing of QRs and neglect of QRs were the top categories of challenges. Conclusion: Management of QRs is significant in ASD and is becoming important in RSD. This study identified research gaps, such as the need for more tools and guidelines, lightweight QR management strategies that fit short iteration cycles, investigations of the link between QRs challenges and technical debt, and extension of empirical validation of existing strategies to a wider context. It also synthesizes QR management strategies and challenges, which may be useful for practitioners.},
   author = {Woubshet Behutiye and Pertti Karhapää and Lidia López and Xavier Burgués and Silverio Martínez-Fernández and Anna Maria Vollmer and Pilar Rodríguez and Xavier Franch and Markku Oivo},
   doi = {10.1016/J.INFSOF.2019.106225},
   issn = {09505849},
   journal = {Information and Software Technology},
   keywords = {Agile software development,Non-functional requirements,Quality requirements,Rapid software development,Systematic literature reviews,Systematic mapping study},
   month = {7},
   publisher = {Elsevier B.V.},
   title = {Management of quality requirements in agile and rapid software development: A systematic mapping study},
   volume = {123},
   year = {2020},
}
@article{Object,
   abstract = {Context: Achieving hundred percent automation in code generation process from Unified Modeling Language (UML) models will make a drastic advancement in software industry. UML does not use a fully formalized semantics. So it leads to ambiguity during automatic implementation of UML models. These ambiguities can be avoided to a large extent using Object Constraint Language (OCL). OCL is formal and user friendly which is also familiar to industry people. Objective: This paper examines how to improve the code generation from UML models, with the help of Object Constraint Language. It also explores the possibilities to incorporate OCL in UML activity models and generate code from the OCL enhanced activity diagrams. Method: Meta models for the association of OCL expressions with the UML activity diagram is proposed in the paper. OCL expressions are added as part of the UML activity models to improve the code generation and to specify assertions and behavior. Moreover a tool, called ActivityOCLKode, is implemented which follows the algorithm for code generation. The algorithm is depicted in the text. Results: The tool which is implemented based on the proposed method gives a promising result. More than 80% of source code is generated using the tool. In addition, the average execution time for our approach is only 11.46 ms. Conclusion: The meta model proposed in the paper gives the strong theoretical back ground to attach OCL statements with each element in the UML activity diagrams. The proposed method of code generation will improve the productivity of the software industries, since it reduces the software development effort and time. Since UML and OCL are commonly used in software industry, our method is easily adaptable by software programmers in industry.},
   author = {E. V. Sunitha and Philip Samuel},
   doi = {10.1016/J.INFSOF.2018.06.010},
   issn = {09505849},
   journal = {Information and Software Technology},
   keywords = {Activity diagram,Code generation,OCL,UML,XML},
   month = {11},
   pages = {92-111},
   publisher = {Elsevier B.V.},
   title = {Object constraint language for code generation from activity models},
   volume = {103},
   year = {2018},
}
@report{Improving,
   abstract = {This paper describes alternative memory semantics for Java programs using an enriched version of the Commit/Reconcile/Fence (CRF) memory model [16]. It outlines a set of reasonable practices for safe multithreaded programming in Java. Our semantics allow a number of optimizations such as load reordering that are currently prohibited. Simple thread-local algebraic rules express the effects of optimizations at the source or bytecode level. The rules focus on reordering source-level operations; they yield a simple dependency analysis algorithm for Java. An instruction-by-instruction translation of Java memory operations into CRF operations captures thread interactions precisely. The fine-grained synchronization of CRF means the algebraic rules are easily derived from the translation. CRF can be mapped directly to a modern architecture, and is thus a suitable target for optimizing memory coherence during code generation.},
   author = {Jan-Willem Maessen and Xiaowei Shen},
   isbn = {0-89791-88-6},
   journal = {OOPSLA},
   keywords = {C12 [Processor Ar-chitectures]: Multiprocessors,D3 [Software]: Programming Languages,D31 [Programming Languages]: Formal Definitions and Theory General Terms Languages, standardization Keywords Memory models, Java, commit/reconcile/fence, compilation},
   title = {Improving the Java Memory Model Using CRF},
   year = {2000},
}
@article{Generative,
   abstract = {Context: Object-oriented domain-driven design (DDD) aims to iteratively develop software around a realistic model of the application domain, which both thoroughly captures the domain requirements and is technically feasible for implementation. The main focus of recent work in DDD has been on using a form of annotation-based domain specific language (aDSL), internal to an object-oriented programming language, to build the domain model. However, these work do not consider software modules as first-class objects and thus lack a method for their development. Objective: In this paper, we tackle software module development with the DDD method by adopting a generative approach that uses aDSL. To achieve this, we first extend a previous work on module-based software architecture with three enhancements that make it amenable to generative development. We then treat module configurations as first-class objects and define an aDSL, named MCCL, to express module configuration classes. To improve productivity, we define function MCCGEN to automatically generate each configuration class from the module's domain class. Method: We define our method as a refinement of an aDSL-based software development method from a previous work. We apply meta-modelling with UML/OCL to define MCCL and implement MCCL in a Java software framework. We evaluate the applicability of our method using a case study and formally define an evaluation framework for module generativity. We also analyse the correctness and performance of function MCCGEN. Results: MCCL is an aDSL for module configurations. Our evaluation shows MCCL is applicable to complex problem domains. Further, the MCCs and software modules can be generated with a high and quantifiable degree of automation. Conclusion: Our method bridges an important gap in DDD with a software module development method that uses a novel aDSL with a module-based software architecture and a generative technique for module configuration.},
   author = {Duc Minh Le and Duc Hanh Dang and Viet Ha Nguyen},
   doi = {10.1016/J.INFSOF.2019.106239},
   issn = {09505849},
   journal = {Information and Software Technology},
   keywords = {Attribute-oriented programming (AtOP),Domain-driven design (DDD),Domain-specific language (DSL),Module-based architecture,Object-oriented programming language (OOPL),UML-based domain modelling},
   month = {4},
   publisher = {Elsevier B.V.},
   title = {Generative software module development for domain-driven design with annotation-based domain specific language},
   volume = {120},
   year = {2020},
}
@article{Feature,
   abstract = {Declarative artifact-centric process models are suitable for specifying knowledge-intensive processes. Currently, such models need to be designed from scratch, even though existing model fragments could be reused to gain efficiency in designing and maintaining declarative artifact-centric process models. To address this problem, this paper proposes an approach for composing model fragments, abstracted into features, into fully specified declarative artifact-centric process models. We use Guard-Stage-Milestone (GSM) schemas as modeling language and let each feature denote a GSM schema fragment. The approach supports feature composition at different levels of granularity. Permutability of features is analyzed. Syntactic conditions that ensure permutability are defined and refactoring of non-permutable into permutable features is discussed. The approach has been evaluated by implementing it in a tool based on the Case Management Model Notation (CMMN) and applying it to three real-world processes. Using the approach, declarative artifact-centric process models can be composed from existing model fragments in an efficient, robust and correct way.},
   author = {Rik Eshuis},
   doi = {10.1016/J.IS.2020.101644},
   issn = {03064379},
   journal = {Information Systems},
   keywords = {Business artifacts,Feature composition,Variability management},
   month = {2},
   publisher = {Elsevier Ltd},
   title = {Feature-oriented engineering of declarative artifact-centric process models},
   volume = {96},
   year = {2021},
}
@article{Topic,
   abstract = {Context: In the last 20 years, the research community has increased its attention to the use of topic modeling for software maintenance and evolution tasks in code. Topic modeling is a popular and promising information retrieval technique that represents topics by word probabilities. Latent Dirichlet Allocation (LDA) is one of the most popular topic modeling methods. However, the use of topic modeling in model-driven software development has been largely neglected. Since software models have less noise (implementation details) than software code, software models might be well-suited for topic modeling. Objective: This paper presents our LDA-guided evolutionary approach for feature location in software models. Specifically, we consider two types of software models: models for code generation and interpreted model. Method: We evaluate our approach considering two real-world industrial case studies: code-generation models for train control software, and interpreted models for a commercial video game. To study the impact on the results, we compare our approach for feature location in models against random search and a baseline based on Latent Semantic Indexing, which is a popular information retrieval technique. In addition, we perform a statistical analysis of the results to show that this impact is significant. We also discuss the results in terms of the following aspects: data sparsity, implementation complexity, calibration, and stability. Results: Our approach significantly outperforms the baseline in terms of recall, precision and F-measure when it comes to interpreted models. This is not the case for code-generation models. Conclusions: Our analysis of the results uncovers a recommendation towards results improvement. We also show that calibration approaches can be transferred from code to models. The findings of our work with regards to the compensation of instability have the potential to help not only feature location in models, but also in code.},
   author = {Francisca Pérez and Raúl Lapeña and Ana C. Marcén and Carlos Cetina},
   doi = {10.1016/J.INFSOF.2021.106676},
   issn = {09505849},
   journal = {Information and Software Technology},
   keywords = {Feature location,Search-based software engineering,Software models,Topic modeling},
   month = {12},
   publisher = {Elsevier B.V.},
   title = {Topic modeling for feature location in software models: Studying both code generation and interpreted models},
   volume = {140},
   year = {2021},
}
@article{JSON,
   abstract = {Despite the fact that JSON is currently one of the most popular formats for exchanging data on the Web, there are very few studies on this topic and there is no agreement upon a theoretical framework for dealing with JSON. Therefore in this paper we propose a formal data model for JSON documents and, based on the common features present in available systems using JSON, we define a lightweight query language allowing us to navigate through JSON documents, study the complexity of basic computational tasks associated with this language, and compare its expressive power with practical languages for managing JSON data.},
   author = {Pierre Bourhis and Juan L. Reutter and Domagoj Vrgoč},
   doi = {10.1016/J.IS.2019.101478},
   issn = {03064379},
   journal = {Information Systems},
   keywords = {JSON,Navigation,Schema languages},
   month = {3},
   publisher = {Elsevier Ltd},
   title = {JSON: Data model and query languages},
   volume = {89},
   year = {2020},
}
@article{XML-based,
   abstract = {Virtual Reality (VR) and Building Information Modelling (BIM) have been steadily growing over the past decade and found practical applications in project planning, design review and construction planning analysis particularly in the Architecture, Engineering, Construction, and Facility Management (AEC/FM) industry. However, data exchange between BIM and VR is a complex and time consuming process, which has limited VR applications in practice. To address this challenge, this research proposes a novel method that enables an efficient interoperability of BIM and VR including geometry of each element along with required semantic data of the BIM model. In this method, geometry and semantic data are extracted from BIM models through an Extensible Markup Language (XML) file, which is then optimized to be efficiently imported and recreated into the VR environment. The backward communication is performed by converting XML file to IFC, which is then imported to the BIM application. A prototype was developed to implement the proposed methodology. A building case study was used to demonstrate the capability of the method including considerably short transfer time, high quality rendering and geo-semantic data exchange for design and construction. These capabilities promote VR applications in the AEC/FM industry as the required information for design and construction plan review including Architectural parameter (e.g., material, texture and dimensions), Engineering parameters (e.g., loads, R-Value), cost, schedule and clashes can be exchanged between BIM and VR in near real time.},
   author = {Alireza Khalili},
   doi = {10.1016/J.AUTCON.2020.103425},
   issn = {09265805},
   journal = {Automation in Construction},
   keywords = {BIM,Geo-semantic,IFC,OpenBIM,Virtual reality,XML},
   month = {1},
   publisher = {Elsevier B.V.},
   title = {An XML-based approach for geo-semantic data exchange from BIM to VR applications},
   volume = {121},
   year = {2021},
}
@article{CoEdit,
   abstract = {Modern compilers can be useful, not only in detecting programming errors but also by suggesting several repairs and solutions for those errors using error repair techniques. Error repair refers to the process of finding a repair for an error that happens as a result of compiling a piece of code written by computer programmers. However, a repair is not always consistent with the purpose of programmers. This means a compiler suggests a repair which is different from what the programmer wanted to write. Many compilers fail to suggest the correct repair when programming errors occur as a result of misspelling errors. The aim of this paper is to enhance the error repair process in compilers using spelling correction algorithms. A typical compiler does not provide solutions for the most common syntax programming errors which occur as a result of misspelling. Such errors are easy to detect by compilers but difficult to suggest a fix that is the correct form. Therefore, a novel error correction mechanism which is called CoEdit approach is developed to help compilers to suggest the most suitable repair for programming errors occurred as a result of mistyping errors. Four-Way and Editex algorithms are well known spelling correction algorithms are also extended and employed to be compatible to work with programming languages. CoEdit approach employs these algorithms in order to find repairs to misspelling errors. CoEdit is a generic approach to enhance error repair in any compilers for any language because it targets misspelling compiler errors. This paper concludes that using the Editex algorithm with CoEdit is the best choice in the case of finding repairs to programming errors that occur as a result of spelling errors.},
   author = {Abdulelah Alwabel},
   doi = {10.1016/J.JKSUCI.2021.02.010},
   issn = {22131248},
   journal = {Journal of King Saud University - Computer and Information Sciences},
   keywords = {Compilers,Edit and compile,Editex,Error enhancing,Error repairs,Four Way},
   publisher = {King Saud bin Abdulaziz University},
   title = {CoEdit: A novel error correction mechanism in compilers using spelling correction algorithms},
   year = {2021},
}
@article{Multi-level,
   abstract = {In many important subject domains, there are central real-world phenomena that span across multiple classification levels. In these subject domains, besides having the traditional type-level domain regularities (classes) that classify multiple concrete instances, we also have higher-order type-level regularities (metaclasses) that classify multiple instances that are themselves types. Multi-Level Modeling aims to address this technical challenge. Despite the advances in this area in the last decade, a number of requirements arising from representation needs in subject domains have not yet been addressed in current modeling approaches. In this paper, we address this issue by proposing an expressive multi-level conceptual modeling language (dubbed ML2). We follow a principled language engineering approach in the design of ML2, constructing its abstract syntax as to reflect a fully axiomatized theory for multi-level modeling (termed MLT*). We show that ML2 enables the expression of a number of multi-level modeling scenarios that cannot be currently expressed in the existing multi-level modeling languages. A textual syntax for ML2 is provided with an implementation in Xtext. We discuss how the formal theory influences the language in two aspects: (i) by providing rigorous justification for the language's syntactic rules, which follow MLT* theorems and (ii) by forming the basis for model simulation and verification. We show that the language can reveal problems in multi-level taxonomic structures, using Wikidata fragments to demonstrate the language's practical relevance.},
   author = {Claudenir M. Fonseca and João Paulo A. Almeida and Giancarlo Guizzardi and Victorio A. Carvalho},
   doi = {10.1016/J.DATAK.2021.101894},
   issn = {0169023X},
   journal = {Data and Knowledge Engineering},
   keywords = {Conceptual modeling,Methodologies and tools,Modeling language,Multi-level modeling},
   month = {7},
   publisher = {Elsevier B.V.},
   title = {Multi-level conceptual modeling: Theory, language and application},
   volume = {134},
   year = {2021},
}
@article{Blended,
   abstract = {Domain-specific modelling languages defined by extending or constraining the Unified Modelling Language (UML) through the profiling mechanism have historically relied on graphical notations to maximise human understanding and facilitate communication among stakeholders. Other notations, such as text-, form-, or table-based are, however, often preferred for specific modelling purposes, due to the nature of a specific domain or the available tooling, or for personal preference. Currently, the state of the art support for UML-based languages provides an almost completely detached, or even entirely mutually exclusive, use of graphical and textual modelling. This becomes inadequate when dealing with the development of modern systems carried out by heterogeneous stakeholders. Our intuition is that a modelling framework based on seamless blended multi-notations can disclose several benefits, among which: flexible separation of concerns, multi-view modelling based on multiple notations, convenient text-based editing operations (inside and outside the modelling environment), and eventually faster modelling activities. In this paper we report on: (i) a proof-of-concept implementation of a framework for UML and profiles modelling using blended textual and graphical notations, and (ii) an experiment on the framework, which eventually shows that blended multi-notation modelling performs better than standard single-notation modelling.},
   author = {Lorenzo Addazi and Federico Ciccozzi},
   doi = {10.1016/J.JSS.2021.110912},
   issn = {01641212},
   journal = {Journal of Systems and Software},
   keywords = {Blended modelling,MARTE,Multi-view modelling,Papyrus,UML profiles,Xtext},
   month = {5},
   publisher = {Elsevier Inc.},
   title = {Blended graphical and textual modelling for UML profiles: A proof-of-concept implementation and experiment},
   volume = {175},
   year = {2021},
}
@article{DeLone,
   abstract = {Considerable research has focused on information system success (ISS) over the years largely using the models proposed by DeLone and McLean (DM) in 1992 and 2003. Several relationships found in the DM models have been sporadically supported in empirical research although the complete DM models have not been consistently applied. Studies have also interchanged relationships in the 1992 and 2003 models, tested relationships between ISS dimensions unspecified in the DM models, and examined relationships between ISS dimensions and other factors. This study presents a critical meta-review of 53 studies using DM models published between 1992 and 2019, identifies the state of ISS research, and raises several directions for research.},
   author = {Anand Jeyaraj},
   doi = {10.1016/J.IJINFOMGT.2020.102139},
   issn = {02684012},
   journal = {International Journal of Information Management},
   keywords = {DeLone and McLean model,Information system success,Meta-review},
   month = {10},
   publisher = {Elsevier Ltd},
   title = {DeLone & McLean models of information system success: Critical meta-review and research directions},
   volume = {54},
   year = {2020},
}
@article{UMLsequence,
   abstract = {Software system and conceptual design are highly abstract and functionally based. In recent years, the software system has been developing rapidly whereas the growth of hardware system is slow. However, it is difficult to transfer the knowledge from software to hardware for conceptual design due to the discipline gaps between software and hardware. Axiomatic design theory bridges software and hardware design conceptually; but lacks in further methodologies for transforming the software system structure to the axiomatic design matrix. This paper focuses on developing a methodology to conceptually design firmware which will help bridge the gap between software and hardware conceptual design. A conversion method between the axiomatic design matrix and the widely used UML sequence diagram was developed. This helps the designers identify Functional Requirements (FRs), Design Parameters (DPs) and their dependencies (i.e., Functional Couplings). In this methodology Functional Messages (FMs) are introduced, defined as the messages of UML sequence diagram and they are used for transition to axiomatic design matrix. DPs of design matrix are defined as the objects in the UML sequence diagram, and FRs of design matrix are generated by merging FMs depending on their flow of information in the sequence diagram. A case study was performed on software system of FDM 3D Printer to validate the proposed method. The UML Sequence diagram of the software system of FDM 3D Printer was successfully transformed into the design matrix. Then Design Coupling Sequence approach was applied to find the proper executable sequence to improve the software design concept of the 3D printer and innovation opportunities were suggested. By using this method, the Software system architecture of FDM 3D Printer was improved conceptually by decoupling the highly coupled DPs, which makes the system more efficient by reducing the build time of a 3D printed part.},
   author = {Rutuja Karampure and Chu Yi Wang and Yash Vashi},
   doi = {10.1016/J.PROCIR.2021.05.104},
   issn = {22128271},
   journal = {Procedia CIRP},
   keywords = {Axiomatic Design,Conceptual Design,Design Coupling Sequence,FDM 3D Printer,Integrated system,Software Design},
   pages = {457-462},
   publisher = {Elsevier B.V.},
   title = {UML sequence diagram to axiomatic design matrix conversion: A method for concept improvement for software in integrated systems},
   volume = {100},
   year = {2021},
}
@article{review,
   abstract = {In the software development life cycle, requirements engineering is the main process that is derived from users by informal interviews written in natural language by requirements engineers (analysts). The requirements may suffer from incompleteness and ambiguity when transformed into formal or semi-formal models that are not well understood by stakeholders. Hence, the stakeholder cannot verify if the formal or semi-formal models satisfy their needs and requirements. Another problem faced by requirements is that when code and/or designs are updated, it is often the case that requirements and specifically the requirements document are not updated. Hence ending with a requirements document not reflecting the implemented software. Generating requirements from the design and/or implementation document is seen by many researchers as a way to address the latter issue. This paper presents a survey of some works undertaken in the field of generation natural language specifications from object UML model using the support of an ontology. and analyzing the robustness and limitations of these existing approaches. This includes studying the generation of natural language from a formal model, review the generation of natural language from ontologies, and finally reviews studies about check to generate natural language from OntoUML.},
   author = {Alaa Abdalazeim and Farid Meziane},
   doi = {10.1016/J.PROCS.2021.05.102},
   issn = {22128271},
   journal = {Procedia CIRP},
   keywords = {Natural Language Generation,Object UML Model,Ontology,Requirements Specification},
   pages = {328-334},
   publisher = {Elsevier B.V.},
   title = {A review of the generation of requirements specification in natural language using objects UML models and domain ontology},
   volume = {189},
   year = {2021},
}
@article{Weighted,
   abstract = {We develop a general framework for weighted parsing which is built on top of grammar-based language models and employs multioperator monoids (M-monoids) as weight algebras. It generalizes previous work in that area, e.g., semiring parsing and weighted deductive parsing, and also covers applications outside the classical scope of parsing, e.g., algebraic dynamic programming. More specifically, we introduce weighted RTG-based language models (where RTG stands for regular tree grammar) and define the M-monoid parsing problem. We show an algorithm which is supposed to solve this problem and prove in detail that, for a large class of weighted RTG-based language models, the algorithm terminates and, indeed, solves this problem. We compare our algorithm with semiring parsing and weighted deductive parsing regarding applicability and complexity.},
   author = {Richard Mörbitz and Heiko Vogler},
   doi = {10.1016/J.IC.2021.104774},
   issn = {10902651},
   journal = {Information and Computation},
   keywords = {Formal grammar,Language model,Weighted parsing},
   month = {12},
   publisher = {Elsevier Inc.},
   title = {Weighted parsing for grammar-based language models over multioperator monoids},
   volume = {281},
   year = {2021},
}
@article{Management,
   abstract = {Context: Quality requirements (QRs) describe the desired quality of software, and they play an important role in the success of software projects. In agile software development (ASD), QRs are often ill-defined and not well addressed due to the focus on quickly delivering functionality. Rapid software development (RSD) approaches (e.g., continuous delivery and continuous deployment), which shorten delivery times, are more prone to neglect QRs. Despite the significance of QRs in both ASD and RSD, there is limited synthesized knowledge on their management in those approaches. Objective: This study aims to synthesize state-of-the-art knowledge about QR management in ASD and RSD, focusing on three aspects: bibliometric, strategies, and challenges. Research method: Using a systematic mapping study with a snowballing search strategy, we identified and structured the literature on QR management in ASD and RSD. Results: We found 156 primary studies: 106 are empirical studies, 16 are experience reports, and 34 are theoretical studies. Security and performance were the most commonly reported QR types. We identified various QR management strategies: 74 practices, 43 methods, 13 models, 12 frameworks, 11 advices, 10 tools, and 7 guidelines. Additionally, we identified 18 categories and 4 non-recurring challenges of managing QRs. The limited ability of ASD to handle QRs, time constraints due to short iteration cycles, limitations regarding the testing of QRs and neglect of QRs were the top categories of challenges. Conclusion: Management of QRs is significant in ASD and is becoming important in RSD. This study identified research gaps, such as the need for more tools and guidelines, lightweight QR management strategies that fit short iteration cycles, investigations of the link between QRs challenges and technical debt, and extension of empirical validation of existing strategies to a wider context. It also synthesizes QR management strategies and challenges, which may be useful for practitioners.},
   author = {Woubshet Behutiye and Pertti Karhapää and Lidia López and Xavier Burgués and Silverio Martínez-Fernández and Anna Maria Vollmer and Pilar Rodríguez and Xavier Franch and Markku Oivo},
   doi = {10.1016/J.INFSOF.2019.106225},
   issn = {09505849},
   journal = {Information and Software Technology},
   keywords = {Agile software development,Non-functional requirements,Quality requirements,Rapid software development,Systematic literature reviews,Systematic mapping study},
   month = {7},
   publisher = {Elsevier B.V.},
   title = {Management of quality requirements in agile and rapid software development: A systematic mapping study},
   volume = {123},
   year = {2020},
}
@article{case,
   abstract = {This study explores the introduction of agile software development within an avionics company engaged in safety-critical system engineering. There is increasing pressure throughout the software industry for development efforts to adopt agile software development in order to respond more rapidly to changing requirements and make more frequent deliveries of systems to customers for review and integration. This pressure is also being experienced in safety-critical industries, where release cycles on typically large and complex systems may run to several years on projects spanning decades. However, safety-critical system developments are normally highly regulated, which may constrain the adoption of agile software development or require adaptation of selected methods or practices. To investigate this potential conflict, we conducted a series of interviews with practitioners in the company, exploring their experiences of adopting agile software development and the challenges encountered. The study also explores the opportunities for altering the existing software process in the company to better fit agile software development to the constraints of software development for safety-critical systems. We conclude by identifying immediate future research directions to better align the tempo of software development for safety-critical systems and agile software development.},
   author = {Gibrail Islam and Tim Storer},
   doi = {10.1016/J.RESS.2020.106954},
   issn = {09518320},
   journal = {Reliability Engineering and System Safety},
   month = {8},
   publisher = {Elsevier Ltd},
   title = {A case study of agile software development for safety-Critical systems projects},
   volume = {200},
   year = {2020},
}
@article{Intelligent,
   abstract = {CONTEXT: Intelligent Software Engineering (ISE) refers to the application of intelligent techniques to software engineering. We define an “intelligent technique” as a technique that explores data (from digital artifacts or domain experts) for knowledge discovery, reasoning, learning, planning, natural language processing, perception or supporting decision-making. OBJECTIVE: The purpose of this study is to synthesize and analyze the state of the art of the field of applying intelligent techniques to Agile Software Development (ASD). Furthermore, we assess its maturity and identify adoption risks. METHOD: Using a systematic literature review, we identified 104 primary studies, resulting in 93 unique studies. RESULTS: We identified that there is a positive trend in the number of studies applying intelligent techniques to ASD. Also, we determined that reasoning under uncertainty (mainly, Bayesian network), search-based solutions, and machine learning are the most popular intelligent techniques in the context of ASD. In terms of purposes, the most popular ones are effort estimation, requirements prioritization, resource allocation, requirements selection, and requirements management. Furthermore, we discovered that the primary goal of applying intelligent techniques is to support decision making. As a consequence, the adoption risks in terms of the safety of the current solutions are low. Finally, we highlight the trend of using explainable intelligent techniques. CONCLUSION: Overall, although the topic area is up-and-coming, for many areas of application, it is still in its infancy. So, this means that there is a need for more empirical studies, and there are a plethora of new opportunities for researchers.},
   author = {Mirko Perkusich and Lenardo Chaves e Silva and Alexandre Costa and Felipe Ramos and Renata Saraiva and Arthur Freire and Ednaldo Dilorenzo and Emanuel Dantas and Danilo Santos and Kyller Gorgônio and Hyggo Almeida and Angelo Perkusich},
   doi = {10.1016/J.INFSOF.2019.106241},
   issn = {09505849},
   journal = {Information and Software Technology},
   keywords = {Agile software development,Artificial intelligence,Bayesian networks,Intelligent software engineering,Machine learning,Search-based software engineering},
   month = {3},
   publisher = {Elsevier B.V.},
   title = {Intelligent software engineering in the context of agile software development: A systematic literature review},
   volume = {119},
   year = {2020},
}
@article{Omg2009,
   author = {Omg},
   isbn = {2009201388},
   title = {An OMG ® Unified Modeling Language ® Publication OMG ® Unified Modeling Language ® (OMG UML ® ) OMG Document Number: Date},
   url = {https://www.omg.org/spec/UML/20161101/PrimitiveTypes.xmi},
   year = {2009},
}
@web_page{tddt4iots,
   author = {G. Guerrero Ulloa and D. Carvajal Suárez and G. Brito Casanova and Pachay Espinoza  A. and J.M. Hornos and Rodríguez Domínguez C},
   title = {Test-Driven Development Tool for IoT-based System},
   url = {https://aplicaciones.uteq.edu.ec/tddt4iots/},
}
@article{Panthi2022,
   abstract = {Quality of developed software totally relies upon three factors the time, effort and testing technique used for testing. Normally in large organizations, the development team allocates a high portion of estimated development time for software testing. Therefore, efficient algorithm needed for designing optimized test scenarios. Proposed approach can be apply on large and complex software. One of the most crucial and tedious task in SDLC is the generation of test scenario specially for large and complex problems. Generation as well as to execution of large number of test cases consumes high portion of effort and duration of total development effort and duration respectively. Therefore automatic testing has become the necessity of software industry specially large scale software development organization to reduce the testing cost to develop qualitative product. Also its very impractical to execute complete set of test case due to limited time and cost, the prioritization of test case is the solution to improve the software quality. Paper proposes a modelling based testing approach to generate test scenarios that uses UML activity diagram (AD). To prioritized the test cases average percentage fault detection (APFD) metrics is used. the proposed approach carries two phases, In the first phase specification information of AD is transferred into an arbitrary and testable graph called activity interaction graph using proposed parser. To execute the second phase a algorithm named TSPACO: the combination of DFS and BFS is proposed. In second phase TSPACO is applied to generate test scenarios with respect to decision and concurrent criteria to prioritize the test scenarios. The proposed model generates prioritized test scenarios according to strength values of different types of activity diagram which are- forks, joins and merge point’, developed by using the proposed TSPACO algorithm. Using the APFD metric, effectiveness of the generated test scenarios is computed. The experimental results shows that test cases generated by proposed approach have 14% more effectiveness than the other existing approaches.},
   author = {Vikas Panthi and Aprna Tripathi and Durga Prasad Mohapatra},
   doi = {10.1007/S13198-021-01551-8},
   issn = {09764348},
   journal = {International Journal of Systems Assurance Engineering and Management},
   keywords = {APFD metric,Activity diagram,Ant colony optimization,Embedded system testing,Test scenarios generation,Test scenarios prioritization},
   month = {8},
   publisher = {Springer},
   title = {Software validation based on prioritization using concurrent activity diagram},
   year = {2022},
}
@article{Chen2022,
   author = {Fangwei Chen and Li Zhang and Xiaoli Lian and Nan Niu},
   doi = {10.1016/J.JSS.2022.111431},
   issn = {01641212},
   journal = {Journal of Systems and Software},
   month = {11},
   pages = {111431},
   title = {Automatically recognizing the semantic elements from UML class diagram images},
   volume = {193},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121222001340},
   year = {2022},
}
@article{Hamdi2022,
   abstract = {Traceability allows engineers to trace and monitor the relationships between software artifacts. Monitoring these relationships is vital to many software engineering activities such as software understanding and reuse. Grasping these relationships is studied in the framework of Requirement Traceability Recovery (RTR). RTR is vital to software reuse as it allows the identification and comparison of requirements of new and existing systems, and hence the reuse of software system components. Due to the difficulties in recovering the traceability links manually, only few software development processes take the monitoring of these relationships fully into account. Many attempts to automate the RTR task that enjoyed some success are based on methods from the field of information retrieval. However, these methods only concentrate on calculating the textual similarity between various software artifacts and do not take into account other properties of the artifacts. In this paper, we propose a search-based RTR approach using genetic algorithms, that relies not only on semantic similarity between software artifacts, but also takes into account the history of reuse of the artifacts, and incorporates knowledge into RTR in the form of user (designer/developer) feedback. Experimental results show that the approach is promising.},
   author = {Mohamed Salah Hamdi and Adnane Ghannem and Marouane Kessentini},
   doi = {10.1007/S11334-021-00418-2},
   issn = {16145054},
   issue = {1},
   journal = {Innovations in Systems and Software Engineering},
   keywords = {Interactive genetic algorithm,Requirements engineering,Requirements traceability,Software reuse},
   month = {3},
   pages = {193-213},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Requirements traceability recovery for the purpose of software reuse: an interactive genetic algorithm approach},
   volume = {18},
   year = {2022},
}
@article{,
   author = {Gustav Bergström and Fadhl Hujainah and Truong Ho-Quang and Rodi Jolak and Satrio Adi Rukmono and Arif Nurwidyantoro and Michel R.V. Chaudron},
   doi = {10.1016/J.JSS.2022.111413},
   issn = {01641212},
   journal = {Journal of Systems and Software},
   month = {10},
   pages = {111413},
   publisher = {Elsevier BV},
   title = {Evaluating the layout quality of UML class diagrams using machine learning},
   year = {2022},
}
@article{Bergstrom2022,
   author = {Gustav Bergström and Fadhl Hujainah and Truong Ho-Quang and Rodi Jolak and Satrio Adi Rukmono and Arif Nurwidyantoro and Michel R.V. Chaudron},
   doi = {10.1016/J.JSS.2022.111413},
   issn = {01641212},
   journal = {Journal of Systems and Software},
   month = {10},
   pages = {111413},
   publisher = {Elsevier BV},
   title = {Evaluating the layout quality of UML class diagrams using machine learning},
   year = {2022},
}
@article{Jahan2021,
   abstract = {Model-driven requirements engineering is gaining enormous popularity in recent years. Unified Modeling Language (UML) is widely used in the software industry for specifying, visualizing, constructing, and documenting the software systems artifacts. UML models are helpful tools for portraying the structure and behavior of a software system. However, generating UML models like Sequence Diagrams from requirements documents often expressed in unstructured natural language, is time consuming and tedious. In this paper, we present an automated approach towards generating behavioral models as UML sequence diagrams from textual use cases written in natural language. The approach uses different Natural Language Processing (NLP) techniques combined with some rule based decision approaches to identify problem level objects and interactions. Additionally, different quality metrics are defined to assess the validity of generated sequence diagrams in terms of expected behaviour from a given use case. The criteria we established to assess the quality of analysis sequence diagrams can be applied to similar experiments. We evaluate our approach using different case studies concerning correctness and completeness of the generated sequence diagrams using those metrics. In most situations, we attained an average accuracy factor of over 85% and average completeness of over 90%, which is encouraging.},
   author = {Munima Jahan and Zahra Shakeri Hossein Abad and Behrouz Far},
   doi = {10.1109/REW53955.2021.00012},
   isbn = {9781665418980},
   issn = {23326441},
   journal = {Proceedings of the IEEE International Conference on Requirements Engineering},
   keywords = {Natural Language Processing,Requirement Engineering,Sequence Diagram,UML model.,Use Case Scenario},
   month = {9},
   pages = {39-48},
   publisher = {IEEE Computer Society},
   title = {Generating Sequence Diagram from Natural Language Requirements},
   volume = {2021-September},
   year = {2021},
}
@article{iqbal2020,
   abstract = {Background: The comprehensive representation of functional requirements is a crucial activity in the analysis phase of the software development life cycle. Representation of a complete set of functional requirements helps in tracing business goals effectively throughout the development life cycle. Use case modelling is one of the most widely-used methods to represent and document functional requirements of the system. Practitioners exploit use case modelling to represent interactive functional requirements of the system while overlooking some of the non-interactive functional requirements. The non-interactive functional requirements are the ones which are performed by the system without an initiation by the user, for instance, notifying something to the user or creating an internal backup. Aim: This paper addresses the representation of non-interactive requirements along with interactive ones (use cases) in one model. This paper calls such requirements 'operation cases' and proposes a new set of graphical and textual notations to represent them. Method: The proposed notations have been applied on a case study and have also been empirically evaluated to demonstrate the effectiveness of the new notations in capturing non-interactive functional requirements. Results and Conclusion: The results of the evaluation indicate that the representation of operation cases helps in documenting a complete set of functional requirements, which ultimately results in a comprehensive translation of requirements into design.},
   author = {Saqib Iqbal and Issam Al-Azzoni and Gary Allen and Hikmat Ullah Khan},
   doi = {10.37190/E-INF200104},
   issn = {20844840},
   issue = {1},
   journal = {E-Informatica Software Engineering Journal},
   keywords = {Use Case modeling UML Requirements Engineering Functional Requirements},
   pages = {97-115},
   publisher = {Wroclaw University of Science and Technology},
   title = {Extending UML use case diagrams to represent non-interactive functional requirements},
   volume = {14},
   year = {2020},
}
@article{Abdelnabi2021,
   abstract = {In the last years, many methods and tools for generating Unified Modeling Language (UML) class diagrams from natural language (NL) software requirements. These methods and tools deal with the transformation of NL textual requirements to UML diagrams. The transformation process involves analyzing NL requirements and extracting relevant information from the text to generate UML class models. This paper aims to survey the existing works of transforming textual requirements into UML class models to indicate their strengths and limitations. The paper provides a comprehensive explanation and evaluation of the existing approaches and tools. The automation degree, efficiency, and completeness, as well as the used techniques, are studied and analyzed. The study demonstrated the necessity of automating the process, in addition to combining artificial intelligence with engineering requirements and using Natural Language Processing (NLP) techniques to extract class diagrams from NL requirements.},
   author = {Esra A. Abdelnabi and Abdelsalam M. Maatuk and Mohammed Hagal},
   doi = {10.1109/MI-STA52233.2021.9464433},
   isbn = {9781665418560},
   journal = {2021 IEEE 1st International Maghreb Meeting of the Conference on Sciences and Techniques of Automatic Control and Computer Engineering, MI-STA 2021 - Proceedings},
   keywords = {NLP,Requirement Engineering,System Development,UML class diagrams},
   month = {5},
   pages = {288-293},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Generating UML Class Diagram from Natural Language Requirements: A Survey of Approaches and Techniques},
   year = {2021},
}
@article{abu2020,
   abstract = {Bus reservation system had actualized in different nations for years, at first from manual to automated reservation system. Online bus ticketing and reservation administrations are adequately expanding in the market since it was propelled by Park May. Now, numerous individuals and organizations are beginning to gain insights of the express bus reservation system. Considering the bus ticket reservation system that has experienced a constant development in the recent years, nevertheless the means for their specifications are still underdeveloped. The Unified Modeling Language (UML) is a language for the specification, visualization and documentation of object-oriented software systems. There is a lot of potential value in UML and diagrams in general. Existing UML diagrams can be utilized to helpfully display conduct. Therefore, in order to understand the development of bus reservation system, it is important to understand what the requirements are on the complete web based bus reservation system. Analyzing the web based bus reservation system by using UML diagrams. Consequently, the nature of theoretical models legitimately influences the nature of the comprehension of the application space and the nature of the last programming items that are at last dependent on them. In this study, we present (web based bus reservation system-UML), the proposed extension to UML covers aspects of use case diagram, sequence diagram, activity diagram and class diagram of the web based bus reservation at the various views and diagrams of UML.},
   author = {Hussain Mohammad Abu-Dalbouh and Sulaiman Abdullah Alateyah},
   doi = {10.3844/JCSSP.2020.825.837},
   issn = {15526607},
   issue = {7},
   journal = {Journal of Computer Science},
   keywords = {Analysis,Design,Developing,Example,Models,Modification,Programming,System,Unified modeling language},
   pages = {825-837},
   publisher = {Science Publications},
   title = {An extension to UML for the modeling of web based bus reservation system},
   volume = {16},
   year = {2020},
}
@article{gonzalez2022,
   author = {Cielo González Moyano and Luise Pufahl and Ingo Weber and Jan Mendling},
   doi = {10.1016/J.INFSOF.2022.107028},
   issn = {0950-5849},
   journal = {Information and Software Technology},
   month = {12},
   pages = {107028},
   publisher = {Elsevier},
   title = {Uses of business process modeling in agile software development projects},
   volume = {152},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584922001483},
   year = {2022},
}
@article{hamza2021,
   abstract = {Software testing is a main phase in the software development life-cycle. Testing tasks are always heavy and time-consuming due to their critical role and importance. Furthermore, testing requires several preparation steps, such as the test sequences. There are many ways to generate the test sequences to perform software testing. In this paper, UML use case diagrams are used to generate test sequences for software testing. The approach is proposed to make use of the UML use case diagrams in more than translating the software requirements to software specifications. The approach consists of several phases. Starting from converting the UML use case diagram into activity diagrams, going through the simplification step, and ending with extracting the needed information to generate the test sequences. The approach is evaluated using nine case studies from a business and systematic perspective. Moreover, the results are compared with the prior work.},
   author = {Zahra Abdulkarim Hamza and Mustafa Hammad},
   doi = {10.12785/IJCDS/100112},
   issn = {2210142X},
   issue = {1},
   journal = {International Journal of Computing and Digital Systems},
   keywords = {Software Engineering,Test Sequences,Testing,UML,Use Case},
   pages = {125-134},
   publisher = {University of Bahrain},
   title = {Analyzing UML use cases to generate test sequences},
   volume = {10},
   year = {2021},
}
@article{,
   abstract = {Traceability in software development proves its importance in many domains like change management, customer's requirements satisfaction, model slicing, etc. Existing traceability techniques trace either between requirement and design or between requirement and code. However, none of the existing approaches achieved reliable results when dealing with traceability between requirements, design models and source code. In this paper, we propose an improvement and an extension of our design traceability approach in order to tackle the traceability between design, requirement and code. The fine-tuning of our methodology stems from considering an expanded textual description. A pre-treatment step is added in order to divide the textual description of system functionalities into different parts, each of which represents a specific goal. In fact, the extension consists in extracting an expanded textual description from a natural language text in order to trace between related elements belonging to requirement, design and code while using an information retrieval technique. The proposed method is based on different scenarios (nominal, alternatives and errors), particularly on concepts related to control structures to establish the traceability between artefacts. Furthermore, we implemented our method in a tool allowing the evaluation of its performance. The evaluation is performed on real existing applications that consist in comparing results found by our approach with results found by experts. Our method achieves an average precision of 0.84 and a recall of 0.91 in traceability between requirement, design and code. Besides its promising performance outcomes, our automated method has the merit of generating a traceability report describing the correspondence between different artefacts. Povzetek: Prispevek opisuje novo metodo za sledenje povezavam med UML diagrami in izvirno kodo.},
   author = {Wiem Khlif and Dhikra Kchaou and Nadia Bouassida},
   doi = {10.31449/inf.v46i1.3306},
   keywords = {UML diagrams,control structure,enriched textual description,traceability,use case},
   title = {A Complete Traceability Methodology Between UML Diagrams and Source Code Based on Enriched Use Case Textual Description},
   url = {https://doi.org/10.31449/inf.v46i1.3306},
}
@web_page{,
   title = {Manifiesto por el Desarrollo Ágil de Software},
   url = {https://agilemanifesto.org/iso/es/manifesto.html},
}
@report{,
   abstract = {One of the main activities of software requirements analysis is requirements prioritization. The wrong requirements prioritization is risky as it leads to many software failures. The current requirements prioritization techniques can't deal with large requirement numbers efficiently, which is considered one of their main issues. Many researchers have agreed that the analytical hierarchy process (AHP) is one of the best prioritization techniques as it produces highly accurate results. AHP has two main problems: scalability and inconsistency. These problems have motivated us to propose an improved version of AHP for software requirements prioritization, namely Enhanced AHP (E-AHP). A performance evaluation has been done for the conventional AHP, E-AHP, and one of the recent algorithms that also try to solve the AHP scalability problems, namely removing eigenvalues and introducing the dynamic consistency checking algorithm into AHP (ReDCCahp) algorithms The evaluation shows which algorithm takes the least time, uses the least memory, produces the most consistent and accurate results, and has the highest scalability. The three algorithms have been evaluated by running their codes using different numbers of requirements ranging from 10 to 500. The results show that E-AHP is more scalable, takes the least time, uses the least memory, and produces the most consistent and accurate results compared to the other two algorithms. That becomes remarkable when the number of requirements increases. Therefore, E-AHP is suitable to be applied in large software projects, as it can deal efficiently with the large software requirements numbers.},
   author = {Nahla Mohamed and Sherif Mazen and Waleed Helmy},
   issue = {7},
   journal = {IJACSA) International Journal of Advanced Computer Science and Applications},
   keywords = {Requirements engineering,analytical hierarchy process,requirements prioritization techniques,software engineering},
   pages = {2022},
   title = {E-AHP: An Enhanced Analytical Hierarchy Process Algorithm for Priotrizing Large Software Requirements Numbers},
   volume = {13},
   url = {www.ijacsa.thesai.org},
}
@article{,
   abstract = {Poorly executed requirements engineering activities profoundly affect the deliverables' quality and project's budget and schedule. High-quality requirements reuse through requirement patterns has been widely discussed to mitigate these adverse outcomes. Requirement patterns aggregate similar applications' behaviors and services into well-defined templates that can be reused in later specifications. The abstraction capabilities of metamodeling have shown promising results concerning the improvement of the requirement specifications' quality and professionals' productivity. However, there is a lack of research on requirement patterns beyond requirements engineering, even using metamodels as the underlying structure. Besides, most companies often struggle with the cost, rework, and delay effects resulting from a weak alignment between requirements and testing. In this paper, we present a novel metamodeling approach, called Software Pattern MetaModel (SoPaMM), which aligns requirements and testing through requirement patterns and test patterns. Influenced by well-established agile practices, SoPaMM describes functional requirement patterns and acceptance test patterns as user stories integrated with executable behaviors. Another novelty is the evaluation of SoPaMM's quality properties against a metamodel quality evaluation framework. We detail the evaluation planning, discuss evaluation results, and present our study's threats to validity. Our experience with the design and evaluation of SoPaMM is summarized as lessons learned.},
   author = {Taciana Novo Kudo and Renato De Freitas Bulcão-Neto and Valdemar Vicente and Graciano Neto and · Auri and Marcelo Rizzo Vincenzi},
   doi = {10.1007/s00766-022-00377-5},
   isbn = {0123456789},
   keywords = {Evaluation,Metamodel,Pattern,Quality,Requirement,Testing},
   pages = {3},
   title = {Aligning requirements and testing through metamodeling and patterns: design and evaluation},
   volume = {1},
   url = {https://doi.org/10.1007/s00766-022-00377-5},
}
@article{Rokis2022,
   abstract = {Low-code/no-code software development is an emerging approach delivering the opportunity to build software with a minimal need for manual coding and enhancing the involvement of non-programmers in software development. Low-code principles allow enterprises to save...},
   author = {Karlis Rokis and Marite Kirikova},
   doi = {10.1007/978-3-031-16947-2_1},
   keywords = {Citizen developer,Low-code,Low-code development platform,No-code,Requirements,Software development},
   pages = {3-17},
   publisher = {Springer, Cham},
   title = {Challenges of Low-Code/No-Code Software Development: A Literature Review},
   url = {https://link.springer.com/chapter/10.1007/978-3-031-16947-2_1},
   year = {2022},
}
@article{Gazzola2022,
   abstract = {Software systems may fail in production environments, causing system crashes, erroneous outputs, and overall system instability. Thoroughly testing software systems in development environments can reduce but not avoid failures, due to both the complexity of software applications, which may lead to a myriad of execution conditions impossible to sample exhaustively, and the many behaviors that emerge in production, which can be hardly predicted and exercised during development. This paper presents field-ready test cases, tests designed to run in production environments, aiming to proactively execute soft-ware components in yet unexplored execution scenarios, exposing error states before they result in system failures. Intuitively, the approach conceives the production environment as a testbed for opportunistically executing unit test cases that exploit the objects that become available as test data. The paper presents the results of a set of experiments with field-ready test cases that we produced for the JFreeChart and Apache Commons Lang libraries. Our field-ready test suites execute 64% of the faults that the original test suites miss, and exposes 33% of the missed faults.},
   author = {Luca Gazzola and Leonardo Mariani and Matteo Orru and Mauro Pezze and Martin Tappler},
   doi = {10.1109/ICST53961.2022.00017},
   isbn = {9781665466790},
   journal = {Proceedings - 2022 IEEE 15th International Conference on Software Testing, Verification and Validation, ICST 2022},
   keywords = {Fault detection,Field testing,Field-Ready test cases},
   pages = {58-69},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Testing Software in Production Environments with Data from the Field},
   year = {2022},
}
@web_page{,
   title = {Manifiesto por el Desarrollo Ágil de Software},
   url = {https://agilemanifesto.org/iso/es/manifesto.html},
}
@article{Shafiq2018,
   abstract = {While analyzing agile projects, documentation mentions towards where the project is driving. The study on document creation, role of the document, document template for process models, the aspect(s) to avoid in documentation, information gathered for the documentation, document requirement format and principles regarding documentation of the process structure including extreme programming (XP), lean, crystal, Feature driven development (FDD), Dynamic Systems Development Method (DSDM), Microsoft Solutions Framework (MSF), Agile Unified Process (AUP), Adaptive Software Development (ASD) in documentation context. The survey will help researchers and practitioners in finding correct strategy for the right process model in the right situation.},
   author = {Muneeb Shafiq and Usman Waheed},
   doi = {10.1109/INMIC.2018.8595625},
   isbn = {9781538675366},
   journal = {Proceedings of the 21st International Multi Topic Conference, INMIC 2018},
   keywords = {Adaptive Software Development (ASD),Agile Unified Process (AUP),Agile method,Dynamic Systems Development Method (DSDM),Feature driven development (FDD),Microsoft Solutions Framework (MSF),crystal,documentation role,documentation template,extreme programming (XP),lean,requirement format},
   month = {12},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Documentation in Agile Development: A Comparative Analysis},
   year = {2018},
}
@article{,
   abstract = {Testing the non-functional requirements (NFR) of a system is particularly complicated and time-consuming. Challenges in this area are compounded when the system is developed under some offspring of Agile methodologies, which favor iterative development and rapid feedback from extensive testing. The authors of this paper build upon previous work investigating the common challenges and solutions cited in recent peer-reviewed research on this topic to design and build a tool consolidating many of the concepts found in this investigation. The tool is known as LuluPerfTest (LPT) and is an NFR testing framework meant to plug into continuous integration (CI) systems to run NFR tests configured with a JSON script. This allows developers and testers to build maintainable and minimally complex automated NFR test scripts. This study explains the challenges inherent in NFR testing in Agile software development and presents how LPT confronts those challenges. It aims to explain LPT and invite collaboration among other testing, verification, and validation researchers to create an open sources software (OSS) solution to the problems of NFR testing in Agile software development projects. CCS CONCEPTS • Software and its engineering; • Software creation and management ; • Software verification and validation;},
   author = {E Whiting and S Datta},
   doi = {10.1145/3520084.3520092},
   isbn = {9781450395519},
   keywords = {Software testing,non-functional requirements,performance testing},
   title = {Design and Development of a Technology-Agnostic NFR Testing Framework Introducing the framework and discussing the future of load testing in Agile software development},
   url = {https://doi.org/10.1145/3520084.3520092},
}
